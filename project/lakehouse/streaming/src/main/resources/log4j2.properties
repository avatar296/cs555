# Log4j2 Configuration for Spark Streaming Applications
# Reduces verbosity of Spark internals while keeping application logs visible

# Root logger - default to WARN
rootLogger.level = WARN
rootLogger.appenderRef.stdout.ref = console

# Console appender configuration
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_OUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Silver Layer Application loggers - keep at INFO for visibility
logger.tripsJob.name = csx55.sta.silver.jobs.TripsCleanedJob
logger.tripsJob.level = INFO

logger.weatherJob.name = csx55.sta.silver.jobs.WeatherCleanedJob
logger.weatherJob.level = INFO

logger.eventsJob.name = csx55.sta.silver.jobs.EventsCleanedJob
logger.eventsJob.level = INFO

logger.abstractJob.name = csx55.sta.silver.jobs.AbstractSilverJob
logger.abstractJob.level = INFO

logger.batchProcessor.name = csx55.sta.silver.batch.BatchProcessor
logger.batchProcessor.level = INFO

logger.validator.name = csx55.sta.silver.validation
logger.validator.level = INFO

logger.quarantine.name = csx55.sta.silver.quarantine
logger.quarantine.level = INFO

logger.metrics.name = csx55.sta.silver.monitoring
logger.metrics.level = INFO

# Bronze Layer Application loggers - keep at INFO for visibility
logger.bronzeJobs.name = csx55.sta.bronze.jobs
logger.bronzeJobs.level = INFO

logger.bronzeAbstract.name = csx55.sta.bronze.jobs.AbstractBronzeJob
logger.bronzeAbstract.level = INFO

# Suppress verbose streaming progress JSON dumps
logger.streaming.name = org.apache.spark.sql.execution.streaming.MicroBatchExecution
logger.streaming.level = WARN

# Suppress checkpoint file manager verbose operations
logger.checkpoint.name = org.apache.spark.sql.execution.streaming.CheckpointFileManager
logger.checkpoint.level = WARN

# Suppress verbose Spark internal loggers
logger.taskSetManager.name = org.apache.spark.scheduler.TaskSetManager
logger.taskSetManager.level = WARN

logger.taskScheduler.name = org.apache.spark.scheduler.TaskSchedulerImpl
logger.taskScheduler.level = WARN

logger.dagScheduler.name = org.apache.spark.scheduler.DAGScheduler
logger.dagScheduler.level = WARN

logger.blockManager.name = org.apache.spark.storage.BlockManager
logger.blockManager.level = WARN

logger.blockManagerInfo.name = org.apache.spark.storage.BlockManagerInfo
logger.blockManagerInfo.level = WARN

logger.executor.name = org.apache.spark.executor.Executor
logger.executor.level = WARN

logger.mapOutput.name = org.apache.spark.MapOutputTrackerMasterEndpoint
logger.mapOutput.level = WARN

logger.sparkContext.name = org.apache.spark.SparkContext
logger.sparkContext.level = WARN

# Keep Iceberg operations at INFO for commit tracking
logger.iceberg.name = org.apache.iceberg
logger.iceberg.level = INFO

# Suppress JDBC catalog view warning
logger.jdbcCatalog.name = org.apache.iceberg.jdbc.JdbcCatalog
logger.jdbcCatalog.level = ERROR

# Keep processing time warnings (useful for performance monitoring)
logger.processingTime.name = org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor
logger.processingTime.level = WARN
